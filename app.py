import gradio as gr
import torch
from transformers import pipeline, AutoModelForCausalLM, AutoTokenizer
from PIL import Image
import numpy as np
from transformers import ViTImageProcessor, ViTForImageClassification

class AIAssistant:
    def __init__(self):
        # ì´ë¯¸ì§€ ë¶„ë¥˜ ëª¨ë¸ ì´ˆê¸°í™”
        self.image_processor = ViTImageProcessor.from_pretrained('google/vit-base-patch16-224')
        self.image_model = ViTForImageClassification.from_pretrained('google/vit-base-patch16-224')
        
        # í…ìŠ¤íŠ¸ ìƒì„± ëª¨ë¸ ì´ˆê¸°í™” (í•œêµ­ì–´ ëª¨ë¸ ì‚¬ìš©)
        self.text_model = pipeline('text-generation', 
                                 model='skt/kogpt2-base-v2',
                                 tokenizer='skt/kogpt2-base-v2')

    def analyze_image(self, image):
        if image is None:
            return "ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”."
        
        # ì´ë¯¸ì§€ ì „ì²˜ë¦¬
        inputs = self.image_processor(images=image, return_tensors="pt")
        outputs = self.image_model(**inputs)
        probs = outputs.logits.softmax(1)
        
        # ìƒìœ„ 3ê°œ ì˜ˆì¸¡ ê²°ê³¼ ê°€ì ¸ì˜¤ê¸°
        top3 = torch.topk(probs, 3)
        results = []
        for i in range(3):
            score = top3.values[0][i].item()
            label = self.image_model.config.id2label[top3.indices[0][i].item()]
            results.append(f"{label}: {score:.2%}")
        
        return "\n".join(results)

    def generate_text(self, prompt):
        if not prompt:
            return "í”„ë¡¬í”„íŠ¸ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”."
        
        # í…ìŠ¤íŠ¸ ìƒì„±
        result = self.text_model(prompt, 
                               max_length=100, 
                               num_return_sequences=1,
                               pad_token_id=self.text_model.tokenizer.pad_token_id)
        
        return result[0]['generated_text']

    def combined_analysis(self, image, prompt):
        # ì´ë¯¸ì§€ ë¶„ì„ê³¼ í…ìŠ¤íŠ¸ ìƒì„±ì„ ê²°í•©
        image_result = self.analyze_image(image)
        text_result = self.generate_text(prompt)
        
        combined = f"ì´ë¯¸ì§€ ë¶„ì„ ê²°ê³¼:\n{image_result}\n\nìƒì„±ëœ í…ìŠ¤íŠ¸:\n{text_result}"
        return combined

# Gradio ì¸í„°í˜ì´ìŠ¤ ìƒì„±
def create_interface():
    assistant = AIAssistant()
    
    with gr.Blocks(title="AI ë„ìš°ë¯¸") as demo:
        gr.Markdown("# ğŸ¤– AI ë„ìš°ë¯¸")
        gr.Markdown("ì´ë¯¸ì§€ ë¶„ì„ê³¼ í…ìŠ¤íŠ¸ ìƒì„±ì„ ë„ì™€ë“œë¦½ë‹ˆë‹¤.")
        
        with gr.Tabs():
            # ì´ë¯¸ì§€ ë¶„ì„ íƒ­
            with gr.Tab("ì´ë¯¸ì§€ ë¶„ì„"):
                with gr.Row():
                    image_input = gr.Image(type="pil", label="ì´ë¯¸ì§€ ì—…ë¡œë“œ")
                    image_output = gr.Textbox(label="ë¶„ì„ ê²°ê³¼")
                image_button = gr.Button("ì´ë¯¸ì§€ ë¶„ì„í•˜ê¸°")
                image_button.click(
                    fn=assistant.analyze_image,
                    inputs=image_input,
                    outputs=image_output
                )
            
            # í…ìŠ¤íŠ¸ ìƒì„± íƒ­
            with gr.Tab("í…ìŠ¤íŠ¸ ìƒì„±"):
                with gr.Row():
                    text_input = gr.Textbox(label="í”„ë¡¬í”„íŠ¸ ì…ë ¥", lines=2)
                    text_output = gr.Textbox(label="ìƒì„±ëœ í…ìŠ¤íŠ¸", lines=5)
                text_button = gr.Button("í…ìŠ¤íŠ¸ ìƒì„±í•˜ê¸°")
                text_button.click(
                    fn=assistant.generate_text,
                    inputs=text_input,
                    outputs=text_output
                )
            
            # í†µí•© ë¶„ì„ íƒ­
            with gr.Tab("í†µí•© ë¶„ì„"):
                with gr.Row():
                    combined_image = gr.Image(type="pil", label="ì´ë¯¸ì§€ ì—…ë¡œë“œ")
                    combined_prompt = gr.Textbox(label="í”„ë¡¬í”„íŠ¸ ì…ë ¥", lines=2)
                combined_output = gr.Textbox(label="í†µí•© ë¶„ì„ ê²°ê³¼", lines=8)
                combined_button = gr.Button("í†µí•© ë¶„ì„í•˜ê¸°")
                combined_button.click(
                    fn=assistant.combined_analysis,
                    inputs=[combined_image, combined_prompt],
                    outputs=combined_output
                )
        
        gr.Markdown("### ì‚¬ìš© ë°©ë²•")
        gr.Markdown("""
        1. ì´ë¯¸ì§€ ë¶„ì„: ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•˜ë©´ ì´ë¯¸ì§€ì˜ ë‚´ìš©ì„ ë¶„ì„í•©ë‹ˆë‹¤.
        2. í…ìŠ¤íŠ¸ ìƒì„±: í”„ë¡¬í”„íŠ¸ë¥¼ ì…ë ¥í•˜ë©´ ê´€ë ¨ëœ í…ìŠ¤íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
        3. í†µí•© ë¶„ì„: ì´ë¯¸ì§€ì™€ í”„ë¡¬í”„íŠ¸ë¥¼ í•¨ê»˜ ì…ë ¥í•˜ë©´ ì¢…í•©ì ì¸ ë¶„ì„ ê²°ê³¼ë¥¼ ì œê³µí•©ë‹ˆë‹¤.
        """)
        
    return demo

# ì¸í„°í˜ì´ìŠ¤ ì‹¤í–‰
if __name__ == "__main__":
    demo = create_interface()
    demo.launch(share=True) 